{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer, load_iris, load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tabpfn.scripts.decision_boundary import DecisionBoundaryDisplay\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from tabpfn.scripts.transformer_prediction_interface import TabPFNClassifier, load_model_workflow, transformer_predict, get_params_from_config\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnDataset(Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = torch.tensor(self.data[index], dtype=torch.float32)\n",
    "        y = torch.tensor(self.target[index], dtype=torch.long)\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Prediction time:  0.3629920482635498 Accuracy 0.96875\n",
      "Prediction time:  0.3910393714904785 Accuracy 1.0\n",
      "Prediction time:  0.38788270950317383 Accuracy 0.984375\n",
      "Prediction time:  0.43715500831604004 Accuracy 0.953125\n",
      "Prediction time:  0.4869370460510254 Accuracy 0.890625\n",
      "Prediction time:  0.4944422245025635 Accuracy 1.0\n",
      "Prediction time:  0.35973501205444336 Accuracy 1.0\n",
      "Prediction time:  0.4930539131164551 Accuracy 1.0\n",
      "Prediction time:  0.49391794204711914 Accuracy 0.9375\n",
      "Prediction time:  0.4987359046936035 Accuracy 0.953125\n",
      "Prediction time:  0.4889719486236572 Accuracy 0.9375\n",
      "Prediction time:  0.4104743003845215 Accuracy 0.984375\n",
      "Prediction time:  0.38995957374572754 Accuracy 1.0\n",
      "Prediction time:  0.2539186477661133 Accuracy 1.0\n",
      "Prediction time:  0.3635904788970947 Accuracy 1.0\n",
      "Prediction time:  0.4484696388244629 Accuracy 0.9375\n",
      "Prediction time:  0.4317033290863037 Accuracy 0.953125\n",
      "Prediction time:  0.43115854263305664 Accuracy 0.9375\n",
      "Prediction time:  0.44419169425964355 Accuracy 0.984375\n",
      "Prediction time:  0.38751840591430664 Accuracy 1.0\n",
      "Prediction time:  0.3006250858306885 Accuracy 1.0\n",
      "Prediction time:  0.4727652072906494 Accuracy 1.0\n",
      "Prediction time:  0.4314558506011963 Accuracy 0.9375\n",
      "Prediction time:  0.39049577713012695 Accuracy 0.953125\n",
      "Prediction time:  0.5675914287567139 Accuracy 0.9375\n",
      "Prediction time:  0.4076099395751953 Accuracy 0.984375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/khaled/Uni/Thesis/repos/TabPFN/tabpfn/task1.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/khaled/Uni/Thesis/repos/TabPFN/tabpfn/task1.ipynb#X24sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/khaled/Uni/Thesis/repos/TabPFN/tabpfn/task1.ipynb#X24sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/khaled/Uni/Thesis/repos/TabPFN/tabpfn/task1.ipynb#X24sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     y_eval, p_eval \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39;49mpredict(x, return_winning_probability\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/khaled/Uni/Thesis/repos/TabPFN/tabpfn/task1.ipynb#X24sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPrediction time: \u001b[39m\u001b[39m'\u001b[39m, time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start, \u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m, accuracy_score(y, y_eval))   \n",
      "File \u001b[0;32m~/Uni/Thesis/repos/TabPFN/tabpfn/scripts/transformer_prediction_interface.py:224\u001b[0m, in \u001b[0;36mTabPFNClassifier.predict\u001b[0;34m(self, X, return_winning_probability, normalize_with_test)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X, return_winning_probability\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, normalize_with_test\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 224\u001b[0m     p \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X, normalize_with_test\u001b[39m=\u001b[39;49mnormalize_with_test)\n\u001b[1;32m    225\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(p, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    226\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39masarray(y, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp))\n",
      "File \u001b[0;32m~/Uni/Thesis/repos/TabPFN/tabpfn/scripts/transformer_prediction_interface.py:205\u001b[0m, in \u001b[0;36mTabPFNClassifier.predict_proba\u001b[0;34m(self, X, normalize_with_test)\u001b[0m\n\u001b[1;32m    201\u001b[0m y_full \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(y_full, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m    203\u001b[0m eval_pos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 205\u001b[0m prediction \u001b[39m=\u001b[39m transformer_predict(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel[\u001b[39m2\u001b[39;49m], X_full, y_full, eval_pos,\n\u001b[1;32m    206\u001b[0m                                  device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice,\n\u001b[1;32m    207\u001b[0m                                  style\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstyle,\n\u001b[1;32m    208\u001b[0m                                  inference_mode\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    209\u001b[0m                                  preprocess_transform\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mnone\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mno_preprocess_mode \u001b[39melse\u001b[39;49;00m \u001b[39m'\u001b[39;49m\u001b[39mmix\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    210\u001b[0m                                  normalize_with_test\u001b[39m=\u001b[39;49mnormalize_with_test,\n\u001b[1;32m    211\u001b[0m                                  N_ensemble_configurations\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mN_ensemble_configurations,\n\u001b[1;32m    212\u001b[0m                                  softmax_temperature\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtemperature,\n\u001b[1;32m    213\u001b[0m                                  combine_preprocessing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_preprocessing,\n\u001b[1;32m    214\u001b[0m                                  multiclass_decoder\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmulticlass_decoder,\n\u001b[1;32m    215\u001b[0m                                  feature_shift_decoder\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_shift_decoder,\n\u001b[1;32m    216\u001b[0m                                  differentiable_hps_as_style\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdifferentiable_hps_as_style,\n\u001b[1;32m    217\u001b[0m                                  seed\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseed,\n\u001b[1;32m    218\u001b[0m                                  \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mget_params_from_config(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mc))\n\u001b[1;32m    219\u001b[0m prediction_, y_ \u001b[39m=\u001b[39m prediction\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m), y_full\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mlong()[eval_pos:]\n\u001b[1;32m    221\u001b[0m \u001b[39mreturn\u001b[39;00m prediction_\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/Uni/Thesis/repos/TabPFN/tabpfn/scripts/transformer_prediction_interface.py:487\u001b[0m, in \u001b[0;36mtransformer_predict\u001b[0;34m(model, eval_xs, eval_ys, eval_position, device, max_features, style, inference_mode, num_classes, extend_features, normalize_with_test, normalize_to_ranking, softmax_temperature, multiclass_decoder, preprocess_transform, categorical_feats, feature_shift_decoder, N_ensemble_configurations, combine_preprocessing, batch_size_inference, differentiable_hps_as_style, average_logits, fp16_inference, normalize_with_sqrt, seed, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    485\u001b[0m                         message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtorch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    486\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 487\u001b[0m     output_batch \u001b[39m=\u001b[39m checkpoint(predict, batch_input, batch_label, style_, softmax_temperature_, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    488\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mautocast(enabled\u001b[39m=\u001b[39mfp16_inference):\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/torch/utils/checkpoint.py:211\u001b[0m, in \u001b[0;36mcheckpoint\u001b[0;34m(function, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mif\u001b[39;00m kwargs:\n\u001b[1;32m    209\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnexpected keyword arguments: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(arg \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m kwargs))\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m CheckpointFunction\u001b[39m.\u001b[39;49mapply(function, preserve, \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/torch/utils/checkpoint.py:90\u001b[0m, in \u001b[0;36mCheckpointFunction.forward\u001b[0;34m(ctx, run_function, preserve_rng_state, *args)\u001b[0m\n\u001b[1;32m     87\u001b[0m ctx\u001b[39m.\u001b[39msave_for_backward(\u001b[39m*\u001b[39mtensor_inputs)\n\u001b[1;32m     89\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 90\u001b[0m     outputs \u001b[39m=\u001b[39m run_function(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     91\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/Uni/Thesis/repos/TabPFN/tabpfn/scripts/transformer_prediction_interface.py:317\u001b[0m, in \u001b[0;36mtransformer_predict.<locals>.predict\u001b[0;34m(eval_xs, eval_ys, used_style, softmax_temperature, return_logits)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mwith\u001b[39;00m inference_mode_call:\n\u001b[1;32m    316\u001b[0m     start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 317\u001b[0m     output \u001b[39m=\u001b[39m model(\n\u001b[1;32m    318\u001b[0m             (used_style\u001b[39m.\u001b[39;49mrepeat(eval_xs\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], \u001b[39m1\u001b[39;49m) \u001b[39mif\u001b[39;49;00m used_style \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, eval_xs, eval_ys\u001b[39m.\u001b[39;49mfloat()),\n\u001b[1;32m    319\u001b[0m             single_eval_pos\u001b[39m=\u001b[39;49meval_position)[:, :, \u001b[39m0\u001b[39m:num_classes]\n\u001b[1;32m    321\u001b[0m     output \u001b[39m=\u001b[39m output[:, :, \u001b[39m0\u001b[39m:num_classes] \u001b[39m/\u001b[39m torch\u001b[39m.\u001b[39mexp(softmax_temperature)\n\u001b[1;32m    322\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_logits:\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Uni/Thesis/repos/TabPFN/tabpfn/transformer.py:141\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[0;34m(self, src, src_mask, single_eval_pos)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_encoder \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     src \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_encoder(src)\n\u001b[0;32m--> 141\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_encoder(src, src_mask)\n\u001b[1;32m    142\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(output)\n\u001b[1;32m    143\u001b[0m \u001b[39mreturn\u001b[39;00m output[single_eval_pos\u001b[39m+\u001b[39m\u001b[39mlen\u001b[39m(style_src)\u001b[39m+\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_att_embeddings\u001b[39m.\u001b[39mnum_embeddings \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_att_embeddings \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m):]\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Uni/Thesis/repos/TabPFN/tabpfn/transformer.py:227\u001b[0m, in \u001b[0;36mTransformerEncoderDiffInit.forward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    224\u001b[0m output \u001b[39m=\u001b[39m src\n\u001b[1;32m    226\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 227\u001b[0m     output \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39;49mmask, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask)\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(output)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Uni/Thesis/repos/TabPFN/tabpfn/layer.py:108\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39massert\u001b[39;00m src_key_padding_mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    107\u001b[0m single_eval_position \u001b[39m=\u001b[39m src_mask\n\u001b[0;32m--> 108\u001b[0m src_left \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(src_[:single_eval_position], src_[:single_eval_position], src_[:single_eval_position])[\u001b[39m0\u001b[39m]\n\u001b[1;32m    109\u001b[0m src_right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_attn(src_[single_eval_position:], src_[:single_eval_position], src_[:single_eval_position])[\u001b[39m0\u001b[39m]\n\u001b[1;32m    110\u001b[0m src2 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([src_left, src_right], dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/activation.py:1031\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1021\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[1;32m   1022\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         q_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_proj_weight, k_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_proj_weight,\n\u001b[1;32m   1029\u001b[0m         v_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv_proj_weight)\n\u001b[1;32m   1030\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1031\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[1;32m   1032\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m   1033\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[1;32m   1034\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[1;32m   1035\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m   1036\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m   1037\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask, need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[1;32m   1038\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask)\n\u001b[1;32m   1039\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first:\n\u001b[1;32m   1040\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/functional.py:5084\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   5082\u001b[0m attn_output, attn_output_weights \u001b[39m=\u001b[39m _scaled_dot_product_attention(q, k, v, attn_mask, dropout_p)\n\u001b[1;32m   5083\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(tgt_len, bsz, embed_dim)\n\u001b[0;32m-> 5084\u001b[0m attn_output \u001b[39m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n\u001b[1;32m   5086\u001b[0m \u001b[39mif\u001b[39;00m need_weights:\n\u001b[1;32m   5087\u001b[0m     \u001b[39m# average attention weights over heads\u001b[39;00m\n\u001b[1;32m   5088\u001b[0m     attn_output_weights \u001b[39m=\u001b[39m attn_output_weights\u001b[39m.\u001b[39mview(bsz, num_heads, tgt_len, src_len)\n",
      "File \u001b[0;32m~/miniconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/functional.py:1847\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_variadic(\u001b[39minput\u001b[39m, weight):\n\u001b[1;32m   1846\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[39minput\u001b[39m, weight), \u001b[39minput\u001b[39m, weight, bias\u001b[39m=\u001b[39mbias)\n\u001b[0;32m-> 1847\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, weight, bias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = SklearnDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_dataset = SklearnDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "classifier = TabPFNClassifier(device='cpu', N_ensemble_configurations=4, only_inference=True)\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    for i,data in enumerate(train_dataloader):\n",
    "        x, y = data\n",
    "        \n",
    "        if i == 0:\n",
    "            classifier.fit(x, y)\n",
    "        \n",
    "        if i != 0:\n",
    "            start = time.time()\n",
    "            y_eval, p_eval = classifier.predict(x, return_winning_probability=True)\n",
    "            print('Prediction time: ', time.time() - start, 'Accuracy', accuracy_score(y, y_eval))   \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample One Batch From Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Prediction time:  0.19298958778381348 Accuracy 0.8\n"
     ]
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=40, test_size=10, random_state=42)\n",
    "\n",
    "classifier = TabPFNClassifier(device='cpu', N_ensemble_configurations=4, only_inference=True)\n",
    "\n",
    "start = time.time()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_eval, p_eval = classifier.predict(X_test, return_winning_probability=True)\n",
    "print('Prediction time: ', time.time() - start, 'Accuracy', accuracy_score(y_test, y_eval))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_string = ''\n",
    "i, e = '8x_lr0.0003', 4\n",
    "base_path = '.'\n",
    "device='cpu'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TabPFN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, c, results_file = load_model_workflow(i, e, add_name=model_string, base_path=base_path, device=device, eval_addition='', only_inference=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Meta Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=40, test_size=10, random_state=42)\n",
    "\n",
    "X, y = check_X_y(X_train, y_train, force_all_finite=False)\n",
    "\n",
    "y = np.asarray(y, dtype=np.float64, order=\"C\")\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "X_test = check_array(X_test, force_all_finite=False)\n",
    "X_full = np.concatenate([X, X_test], axis=0)\n",
    "X_full = torch.tensor(X_full, device=device, requires_grad=True).float().unsqueeze(1)\n",
    "y_full = np.concatenate([y, np.zeros_like(X[:, 0])], axis=0)\n",
    "y_full = torch.tensor(y_full, device=device, requires_grad=True).float().unsqueeze(1)\n",
    "eval_position = X.shape[0]\n",
    "\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model[2].train()\n",
    "optimizer = optim.Adam(model[2].parameters(), lr=0.001)\n",
    "for e in range (10):\n",
    "    optimizer.zero_grad()\n",
    "    prediction = transformer_predict(model[2], X_full, y_full, eval_position,\n",
    "                            device='cpu',\n",
    "                            style=None,\n",
    "                            inference_mode=False,\n",
    "                                    N_ensemble_configurations=3,\n",
    "                            softmax_temperature=None, **get_params_from_config(c))\n",
    "\n",
    "    loss = criterion( prediction.squeeze(0),y_test)\n",
    "    print(e, '|', loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = TabPFNClassifier(device='cpu', N_ensemble_configurations=4, only_inference=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=40, test_size=10, random_state=42)\n",
    "\n",
    "classifier.model[2].train()\n",
    "\n",
    "y_test = torch.from_numpy(y_test)\n",
    "optimizer = optim.Adam(classifier.model[2].parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for e in range (100):\n",
    "    optimizer.zero_grad()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    prediction = classifier.predict_proba2(X_test)\n",
    "    prediction = prediction.squeeze(0)\n",
    "    loss = criterion(prediction,y_test)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, params in classifier.model[2].named_parameters():\n",
    "    print('name :', name , \"|\" 'params :', params.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_eval, p_eval = classifier.predict(X_test, return_winning_probability=True)\n",
    "print('Prediction time: ', time.time() - start, 'Accuracy', accuracy_score(y_test, y_eval))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
